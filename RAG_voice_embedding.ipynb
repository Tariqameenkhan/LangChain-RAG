{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tariqameenkhan/LangChain-RAG/blob/main/RAG_voice_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "raw",
      "id": "61ec23a2",
      "metadata": {
        "id": "61ec23a2"
      },
      "source": [
        "https://samueldamilare.medium.com/mastering-vector-embeddings-search-text-audio-video-and-images-with-ease-1f1b9f3ec55d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17285300",
      "metadata": {
        "id": "17285300"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq tensorflow_hub  pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a415bd2",
      "metadata": {
        "id": "0a415bd2"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq tensorflow-io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099a8f73",
      "metadata": {
        "id": "099a8f73",
        "outputId": "d0d63405-3ae8-4b5e-e006-4697b0ff0736"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-09 13:41:25.495832: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
            "2024-10-09 13:41:25.495854: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2024-10-09 13:41:25.495860: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2024-10-09 13:41:25.495877: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-10-09 13:41:25.495884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
            "2024-10-09 13:41:26.761307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embedding shape: (34, 1024)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load the YAMNET model\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Load an audio file\n",
        "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audio/h1.wav'))\n",
        "audio = tf.squeeze(audio, axis=-1)\n",
        "\n",
        "# Generate embeddings\n",
        "scores, embeddings, log_mel_spectrogram = model(audio)\n",
        "\n",
        "print(f\"Audio embedding shape: {embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3df3238",
      "metadata": {
        "id": "e3df3238",
        "outputId": "ec8b9b7a-6a11-446e-8b61-3e5c9b913c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embedding shape: (41, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Load an audio file\n",
        "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audio/a2.wav'))\n",
        "audio = tf.squeeze(audio, axis=-1)\n",
        "\n",
        "scores, embeddings, log_mel_spectrogram = model(audio)\n",
        "\n",
        "print(f\"Audio embedding shape: {embeddings.shape}\")#27,18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0781c9f",
      "metadata": {
        "id": "f0781c9f",
        "outputId": "e2312256-a7c7-4f22-c380-60415435721d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2016, 64), dtype=float32, numpy=\n",
              "array([[-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
              "        -6.9077554],\n",
              "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
              "        -6.9077554],\n",
              "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
              "        -6.9077554],\n",
              "       ...,\n",
              "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
              "        -6.9077554],\n",
              "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
              "        -6.9077554],\n",
              "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
              "        -6.9077554]], dtype=float32)>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_mel_spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235d4679",
      "metadata": {
        "id": "235d4679"
      },
      "source": [
        "#  we found shape dimension error\n",
        "* you can solve with slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5383fe62",
      "metadata": {
        "id": "5383fe62",
        "outputId": "06578212-9c10-4a57-d1d3-b686bc456e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio embedding shape: (41, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
            "a2.wav\n",
            "Audio embedding shape: (29, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
            "a1.wav\n",
            "Audio embedding shape: (34, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
            "h1.wav\n",
            "Audio embedding shape: (18, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
            "q2.wav\n",
            "Audio embedding shape: (42, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
            "h2.wav\n",
            "Audio embedding shape: (27, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
            "q1.wav\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "voices = []\n",
        "labels = []\n",
        "for i in os.listdir(\"./audio/\"):\n",
        "    if '.wav' in i:\n",
        "        name = i.split(\".\")[0]\n",
        "\n",
        "\n",
        "        audio, sample_rate = tf.audio.decode_wav(tf.io.read_file(f'./audio/{i}'))\n",
        "        audio = tf.squeeze(audio, axis=-1)\n",
        "\n",
        "        scores, embeddings, log_mel_spectrogram = model(audio)\n",
        "\n",
        "        voices.append(np.array(embeddings[:5,:]).ravel())\n",
        "        labels.append(name)\n",
        "\n",
        "        print(f\"Audio embedding shape: {embeddings.shape} new shape {embeddings[:5,:].shape} type {type(np.array(embeddings[:18,:]))}\")#27,18\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da7e4a33",
      "metadata": {
        "id": "da7e4a33",
        "outputId": "9e777ace-07ec-4e46-878b-6892d0591da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([1.6946361 , 0.36075723, 0.6930015 , ..., 0.9783664 , 0.12747997,\n",
              "        0.        ], dtype=float32),\n",
              " array([0.        , 0.25089428, 0.09453958, ..., 0.        , 0.        ,\n",
              "        0.        ], dtype=float32),\n",
              " array([2.2192965 , 0.14239739, 0.6774485 , ..., 0.        , 0.        ,\n",
              "        0.        ], dtype=float32),\n",
              " array([2.103551  , 0.28917295, 0.66041994, ..., 0.        , 0.        ,\n",
              "        0.        ], dtype=float32),\n",
              " array([1.8627615 , 0.10154425, 0.7127788 , ..., 0.2883861 , 1.3826851 ,\n",
              "        2.7965832 ], dtype=float32),\n",
              " array([2.324272  , 0.17074186, 0.21542566, ..., 0.0181713 , 1.7490327 ,\n",
              "        1.825291  ], dtype=float32)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a47001",
      "metadata": {
        "id": "a4a47001"
      },
      "outputs": [],
      "source": [
        "#Imports a PyMilvus package:\n",
        "from pymilvus import (\n",
        "    connections,\n",
        "    utility,\n",
        "    FieldSchema,\n",
        "    CollectionSchema,\n",
        "    DataType,\n",
        "    Collection,\n",
        ")\n",
        "\n",
        "#Connect to the Milvus\n",
        "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
        "# Define the collection name\n",
        "collection_name = \"audio\"\n",
        "\n",
        "# Delete old collection if it exists\n",
        "if utility.has_collection(collection_name):\n",
        "    Collection(collection_name).drop()\n",
        "\n",
        "\n",
        "#Creates a collection:\n",
        "fields = [\n",
        "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
        "    FieldSchema(name=\"words\", dtype=DataType.VARCHAR, max_length=50),\n",
        "    FieldSchema(name=\"person_name\", dtype=DataType.VARCHAR, max_length=50),\n",
        "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=5120)\n",
        "]\n",
        "schema = CollectionSchema(fields, \"Simple Demo for audio similar search\")\n",
        "audio = Collection(\"audio\", schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6ff703",
      "metadata": {
        "id": "7c6ff703",
        "outputId": "8f0add8e-fe98-475b-835e-14718d33aa59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Status(code=0, message=)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Builds indexes on the entities:\n",
        "\n",
        "index = {\n",
        "    \"index_type\": \"IVF_FLAT\",\n",
        "    \"metric_type\": \"L2\",\n",
        "    \"params\": {\"nlist\": 128},\n",
        "}\n",
        "\n",
        "audio.create_index(\"embeddings\", index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a067e1",
      "metadata": {
        "id": "38a067e1",
        "outputId": "28441dd1-e70b-4980-b9ef-821c97c62521"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a2', 'a1', 'h1', 'q2', 'h2', 'q1']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63acee52",
      "metadata": {
        "id": "63acee52",
        "outputId": "77e950ce-b163-4f8e-8326-3d327ca1f014"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5120,)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voices[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "498bb584",
      "metadata": {
        "id": "498bb584"
      },
      "outputs": [],
      "source": [
        "#Insert data in collection\n",
        "data = [\n",
        "    [1,2,3,4,5,6],  # field pk\n",
        "    labels,  # field words\n",
        "    [\"Auranzaib\",\"Auranzaib\",\"Hasnant\",\"Qasim\",\"Hasnant\",\"Qasim\"],\n",
        "    voices,  # field embeddings\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1cecb9",
      "metadata": {
        "id": "7f1cecb9"
      },
      "outputs": [],
      "source": [
        "audio.insert(data)\n",
        "audio.flush()\n",
        "audio.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add38b06",
      "metadata": {
        "id": "add38b06"
      },
      "outputs": [],
      "source": [
        "search_params = {\"metric_type\": \"L2\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8629381c",
      "metadata": {
        "id": "8629381c"
      },
      "outputs": [],
      "source": [
        "results = audio.search(\n",
        "\tdata=[voices[0]],\n",
        "\tanns_field=\"embeddings\",\n",
        "\tparam=search_params,\n",
        "\tlimit=4,\n",
        "\texpr=None,\n",
        "\t# set the names of the fields you want to retrieve from the search result.\n",
        "\toutput_fields=['words','person_name'],\n",
        "\tconsistency_level=\"Strong\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "760df8e0",
      "metadata": {
        "id": "760df8e0",
        "outputId": "11f1faa9-7737-49d8-f638-c6da954d2047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auranzaib\n",
            "Auranzaib\n",
            "Qasim\n",
            "Hasnant\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,len(results[0])):\n",
        "    name = results[0][i].entity.get('words')\n",
        "    pname = results[0][i].entity.get('person_name')\n",
        "    print(pname)\n",
        "#     try:\n",
        "#         display(Image.open('./images/'+name+'.jpg'))\n",
        "#     except:\n",
        "#         display(Image.open('./images/'+name+'.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1c4b0b",
      "metadata": {
        "id": "7b1c4b0b",
        "outputId": "4f8e2d09-14a9-42b3-af77-0565abb47f32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a2', 'a1', 'h1', 'q2', 'h2', 'q1']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396e25d4",
      "metadata": {
        "id": "396e25d4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}